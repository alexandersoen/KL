Environment:
	Python: 3.6.8
	PyTorch: 1.8.1+cu111
	Torchvision: 0.9.1+cu111
	CUDA: 11.1
	CUDNN: 8005
	NumPy: 1.19.5
	PIL: 8.3.1
Args:
	algorithm: KL
	checkpoint_freq: None
	data_dir: /scratch/local/ssd/tuan/data/
	dataset: RotatedMNIST
	epochs: None
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 14
	output_dir: ./results_sweep/18a38615435e4a7492ad0dfbf4b3f74f
	save_model_every_checkpoint: False
	seed: 168555330
	skip_model_save: False
	steps: None
	task: domain_adaptation
	test_envs: [4]
	train_envs: [0]
	trial_seed: 2
	uda_holdout_fraction: 0
HParams:
	augment_softmax: 0.01
	batch_size: 256
	class_balanced: False
	data_augmentation: True
	kl_reg: 0.3
	kl_reg_aux: 0.1
	lr: 0.0011903665081302557
	nonlinear_classifier: False
	num_samples: 20
	resnet18: True
	resnet_dropout: 0.5
	specify_zdim: True
	weight_decay: 0.0
	z_dim: 512
cuda
/homes/55/tuan/installations/tnew/lib64/python3.6/site-packages/torchvision/transforms/functional.py:936: UserWarning: Argument resample is deprecated and will be removed since v0.10.0. Please, use interpolation instead
  "Argument resample is deprecated and will be removed since v0.10.0. Please, use interpolation instead"
env0_out_acc  env4_in_acc   env4_out_acc  epoch         kl            kl_aux        loss          step          step_time    
0.1307329619  0.1160398586  0.1174453493  0.0000000000  1.3976144791  1.6630570889  2.4152836800  0             0.6278893948 
0.1980282898  0.2002571520  0.2186026575  1.0000000000  0.0741814011  0.0813391474  2.3316496015  36            0.1271267864 
0.2584654951  0.2527590271  0.2696099443  2.0000000000  0.0823268063  0.1120343341  2.0729904473  72            0.1233295202 
0.2704672096  0.2641165756  0.2738962709  3.0000000000  0.0874308944  0.1117423938  1.9378965166  108           0.1249371303 
0.3377625375  0.3250830387  0.3437633948  4.0000000000  0.0927039352  0.0951951146  1.8616901967  144           0.1232877970 
0.3703386198  0.3442622951  0.3720531505  5.0000000000  0.1235830718  0.1175923745  1.8055628439  180           0.1247646875 
0.4097728247  0.3684774456  0.4042006001  6.0000000000  0.1384718981  0.1352841059  1.7346299026  216           0.1278582745 
0.4466352336  0.3621557913  0.3810544363  7.0000000000  0.2070340316  0.2196775311  1.6077718172  252           0.1277536352 
0.5032147450  0.4008357441  0.4307758251  8.0000000000  0.2447219524  0.2561103602  1.5239494973  288           0.1306514343 
0.5435062152  0.4085503054  0.4350621517  9.0000000000  0.2862280574  0.2930744323  1.3817701439  324           0.1274717318 
0.5975139306  0.4146576663  0.4462066009  10.000000000  0.3168452316  0.3384734690  1.2432775663  360           0.1272226175 
0.6875267895  0.4329797493  0.4586369481  11.000000000  0.3452441494  0.3884687920  1.1437617044  396           0.1268207100 
0.7655379340  0.4314796957  0.4654950707  12.000000000  0.3908485572  0.4257203043  1.0647154036  432           0.1303820544 
0.7796828118  0.4382299368  0.4719245607  13.000000000  0.4181124038  0.4834530320  1.0026355998  468           0.1282027894 
0.8349764252  0.4769098896  0.5002143163  14.000000000  0.4346050123  0.4999075101  0.8579510384  504           0.1289006074 
0.8641234462  0.4779813565  0.4954993571  15.000000000  0.4316040311  0.4807291859  0.7978126589  540           0.1284887791 
0.8954136305  0.5122682953  0.5516502357  16.000000000  0.4672242502  0.4910562336  0.7100221117  576           0.1275435421 
0.9018431204  0.5552341155  0.5777968281  17.000000000  0.4495623244  0.4657406145  0.6480148799  612           0.1281435357 
Traceback (most recent call last):
  File "/usr/lib64/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib64/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/homes/55/tuan/KL/scripts/train.py", line 236, in <module>
    step_vals = algorithm.update(minibatches_device, uda_device)
  File "/homes/55/tuan/KL/algorithms.py", line 229, in update
    obj.backward()
  File "/homes/55/tuan/installations/tnew/lib64/python3.6/site-packages/torch/tensor.py", line 245, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/homes/55/tuan/installations/tnew/lib64/python3.6/site-packages/torch/autograd/__init__.py", line 147, in backward
    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag
KeyboardInterrupt
