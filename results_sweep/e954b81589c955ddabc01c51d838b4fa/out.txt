Environment:
	Python: 3.6.8
	PyTorch: 1.8.1+cu111
	Torchvision: 0.9.1+cu111
	CUDA: 11.1
	CUDNN: 8005
	NumPy: 1.19.5
	PIL: 8.3.1
Args:
	algorithm: KL
	checkpoint_freq: None
	data_dir: /scratch/local/ssd/tuan/data/
	dataset: RotatedMNIST
	epochs: None
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 2
	output_dir: ./results_sweep/e954b81589c955ddabc01c51d838b4fa
	save_model_every_checkpoint: False
	seed: 132629544
	skip_model_save: False
	steps: None
	task: domain_adaptation
	test_envs: [4]
	train_envs: [0]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	augment_softmax: 0.01
	batch_size: 256
	class_balanced: False
	data_augmentation: True
	kl_reg: 0.3
	kl_reg_aux: 0.1
	lr: 0.0003207929136369226
	nonlinear_classifier: False
	num_samples: 20
	resnet18: True
	resnet_dropout: 0.5
	specify_zdim: False
	weight_decay: 0.0
	z_dim: 16
cuda
/homes/55/tuan/installations/tnew/lib64/python3.6/site-packages/torchvision/transforms/functional.py:936: UserWarning: Argument resample is deprecated and will be removed since v0.10.0. Please, use interpolation instead
  "Argument resample is deprecated and will be removed since v0.10.0. Please, use interpolation instead"
env0_out_acc  env4_in_acc   env4_out_acc  epoch         kl            kl_aux        loss          step          step_time    
0.1105872267  0.1051108968  0.0981568796  0.0000000000  0.0246756412  0.0252149813  2.3608818054  0             1.7083504200 
0.2781825975  0.2051858995  0.2036005144  1.0000000000  0.0259229980  0.0314331418  2.2585675187  36            0.0409214430 
0.4183454779  0.2185792350  0.2160308616  2.0000000000  0.0478238370  0.0520068607  2.1083863576  72            0.0421130988 
0.5263609087  0.2212579021  0.2078868410  3.0000000000  0.0760200616  0.0802043506  2.0013952288  108           0.0419989692 
0.5332190313  0.2046501661  0.1903129018  4.0000000000  0.0830993361  0.0872257459  1.9017242458  144           0.0419403911 
0.5957993999  0.2144005143  0.2156022289  5.0000000000  0.1098804262  0.1242061932  1.7838725183  180           0.0396627453 
0.5936562366  0.2296153434  0.2224603515  6.0000000000  0.1524285150  0.1818603205  1.6439011428  216           0.0411656234 
0.7175310759  0.2283295832  0.2237462495  7.0000000000  0.2005855851  0.2058714425  1.5564122233  252           0.0420104133 
0.7411058723  0.2505089467  0.2374624946  8.0000000000  0.2153104175  0.2332670713  1.4235511555  288           0.0418459972 
0.7981140163  0.2485803064  0.2456065152  9.0000000000  0.2173663129  0.2469159882  1.3239823580  324           0.0431818763 
0.8315473639  0.2590806815  0.2438919846  10.000000000  0.2580573844  0.2747090297  1.2509147194  360           0.0441705651 
0.8662666095  0.2760098575  0.2563223318  11.000000000  0.2700288623  0.2798092957  1.1544476383  396           0.0428272751 
0.8774110587  0.3009750348  0.2846120874  12.000000000  0.2788769694  0.2997461102  1.0944778257  432           0.0422887140 
0.8834119160  0.3001178614  0.2953279040  13.000000000  0.3005983105  0.3206732786  1.0297568225  468           0.0441794462 
0.8846978140  0.2857602057  0.2571795971  14.000000000  0.2992360236  0.3005638657  0.9661655575  504           0.0443791416 
0.8984140592  0.2832958320  0.2751821689  15.000000000  0.3189375430  0.3299253206  0.9159153402  540           0.0424398118 
0.9027003858  0.3345119469  0.3240462923  16.000000000  0.3532348540  0.3552550524  0.8602961236  576           0.0416004459 
0.8988426918  0.2962605807  0.2721817402  17.000000000  0.3385094164  0.3573079415  0.8123949054  612           0.0502453711 
0.9185597943  0.2992606879  0.2858979854  18.000000000  0.3449538011  0.3659512682  0.7715747241  648           0.0439507630 
0.9078439777  0.3180113575  0.3013287613  19.000000000  0.3436160543  0.3524824791  0.7415439801  684           0.0437036951 
0.9065580797  0.3299046395  0.3146163738  20.000000000  0.3417497116  0.3641194594  0.7023114463  720           0.0427094367 
0.9275610802  0.3244401586  0.3086155165  21.000000000  0.3579672600  0.3334635976  0.6774570561  756           0.0411351323 
0.9095585084  0.3209043180  0.3094727818  22.000000000  0.3797843746  0.3726571463  0.6427182853  792           0.0404850443 
0.9267038148  0.3217614915  0.3103300471  23.000000000  0.3811847907  0.3505203235  0.6263365232  828           0.0429187616 
0.9348478354  0.3214400514  0.2983283326  24.000000000  0.3723537351  0.3361633279  0.6005387372  864           0.0462893248 
0.9339905701  0.3265830923  0.3094727818  25.000000000  0.3439686948  0.3315734255  0.5895395660  900           0.0466533369 
0.9292756108  0.3404050145  0.3266180883  26.000000000  0.3662488597  0.3463809333  0.5571155209  936           0.0420208971 
0.9369909987  0.3424408015  0.3266180883  27.000000000  0.3580857731  0.3458023241  0.5495467799  972           0.0434941120 
0.9352764681  0.3551912568  0.3330475782  28.000000000  0.3555845014  0.3496531679  0.5264105242  1008          0.0454703768 
0.9309901414  0.3453337619  0.3219031290  29.000000000  0.3749377189  0.3403240475  0.5321847010  1044          0.0414577789 
0.9348478354  0.3165113040  0.2944706387  30.000000000  0.3599848499  0.3326375232  0.4982526029  1080          0.0471009745 
0.9421345907  0.3446908818  0.3201885984  31.000000000  0.3511484721  0.3219892072  0.4787006974  1116          0.0572290156 
0.9472781826  0.3474766956  0.3274753536  32.000000000  0.3430330662  0.3254107961  0.4877406988  1152          0.0413834651 
0.9395627947  0.3168327440  0.2957565366  33.000000000  0.3491635670  0.3082756495  0.4680666402  1188          0.0434573293 
0.9425632233  0.3290474660  0.3069009859  34.000000000  0.3482844921  0.3162358614  0.4457824131  1224          0.0420123670 
0.9369909987  0.3564770170  0.3373339048  35.000000000  0.3401113277  0.3151549978  0.4264437159  1260          0.0411646234 
0.9404200600  0.3557269902  0.3364766395  36.000000000  0.3444502292  0.3035466183  0.4271855445  1296          0.0430957940 
0.9412773253  0.3324761599  0.3103300471  37.000000000  0.3227642626  0.2868345078  0.4079534337  1332          0.0466717813 
0.9468495499  0.3407264545  0.3201885984  38.000000000  0.3509162540  0.3317523524  0.4000245896  1368          0.0427536170 
Traceback (most recent call last):
  File "/usr/lib64/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib64/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/homes/55/tuan/KL/scripts/train.py", line 236, in <module>
    step_vals = algorithm.update(minibatches_device, uda_device)
  File "/homes/55/tuan/KL/algorithms.py", line 201, in update
    z_dist = dist.Independent(dist.normal.Normal(z_mu,z_sigma),1)
  File "/homes/55/tuan/installations/tnew/lib64/python3.6/site-packages/torch/distributions/normal.py", line 50, in __init__
    super(Normal, self).__init__(batch_shape, validate_args=validate_args)
  File "/homes/55/tuan/installations/tnew/lib64/python3.6/site-packages/torch/distributions/distribution.py", line 52, in __init__
    if not constraint.check(getattr(self, param)).all():
KeyboardInterrupt
