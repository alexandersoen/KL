Environment:
	Python: 3.6.8
	PyTorch: 1.8.1+cu111
	Torchvision: 0.9.1+cu111
	CUDA: 11.1
	CUDNN: 8005
	NumPy: 1.19.5
	PIL: 8.3.1
Args:
	algorithm: KL
	checkpoint_freq: None
	data_dir: /scratch/local/ssd/tuan/data/
	dataset: RotatedMNIST
	epochs: None
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_adaptation
	test_envs: [1]
	train_envs: [0]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	augment_softmax: 0.0
	batch_size: 256
	class_balanced: False
	data_augmentation: True
	kl_reg: 0.3
	kl_reg_aux: 0.1
	lr: 0.001
	nonlinear_classifier: False
	num_samples: 20
	resnet18: True
	resnet_dropout: 0.0
	specify_zdim: True
	weight_decay: 0.0
	z_dim: 256
cuda
/homes/55/tuan/installations/tnew/lib64/python3.6/site-packages/torchvision/transforms/functional.py:936: UserWarning: Argument resample is deprecated and will be removed since v0.10.0. Please, use interpolation instead
  "Argument resample is deprecated and will be removed since v0.10.0. Please, use interpolation instead"
env0_out_acc  env1_in_acc   env1_out_acc  epoch         kl            kl_aux        loss          step          step_time    
0.0994427775  0.0971716306  0.1157308187  0.0000000000  0.0944107771  0.1641414165  2.4799859524  0             1.8403139114 
0.3420488641  0.3361902721  0.3274753536  1.0000000000  0.0879710648  0.0924681889  2.1158065399  36            0.0952420367 
0.4903557651  0.4438611528  0.4337762538  2.0000000000  0.1462483307  0.1539480951  1.7632114424  72            0.0780343877 
0.6078011144  0.5695307478  0.5803686241  3.0000000000  0.2595527007  0.2818110039  1.4773057467  108           0.0778162877 
0.8139734248  0.7629097922  0.7591084441  4.0000000000  0.3306724131  0.3515780585  1.2004646593  144           0.0768888725 
0.8448349764  0.7834797514  0.7839691384  5.0000000000  0.3829663843  0.3941949010  0.9286385576  180           0.0773972207 
0.9048435491  0.8749732162  0.8748392628  6.0000000000  0.3800443444  0.3774077959  0.7752707667  216           0.0779599415 
0.9335619374  0.9104349689  0.9112730390  7.0000000000  0.3958977179  0.3914909628  0.6566232501  252           0.0772358245 
0.9399914273  0.9217913006  0.9142734676  8.0000000000  0.3906334341  0.3829743448  0.5110336923  288           0.0777331922 
0.9434204886  0.9351832012  0.9309901414  9.0000000000  0.3908217682  0.3622196648  0.4322703315  324           0.0775214897 
0.9549935705  0.9376473109  0.9434204886  10.000000000  0.3641511218  0.3503231456  0.3748219560  360           0.0781119929 
0.9614230604  0.9450396400  0.9421345907  11.000000000  0.3672090371  0.3443993313  0.3457045924  396           0.0781233046 
0.9592798971  0.9475037497  0.9472781826  12.000000000  0.3464296112  0.3485446821  0.3143691044  432           0.0772256653 
Traceback (most recent call last):
  File "/usr/lib64/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib64/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/homes/55/tuan/KL/scripts/train.py", line 236, in <module>
    step_vals = algorithm.update(minibatches_device, uda_device)
  File "/homes/55/tuan/KL/algorithms.py", line 192, in update
    z_dist = dist.Independent(dist.normal.Normal(z_mu,z_sigma),1)
  File "/homes/55/tuan/installations/tnew/lib64/python3.6/site-packages/torch/distributions/normal.py", line 50, in __init__
    super(Normal, self).__init__(batch_shape, validate_args=validate_args)
  File "/homes/55/tuan/installations/tnew/lib64/python3.6/site-packages/torch/distributions/distribution.py", line 52, in __init__
    if not constraint.check(getattr(self, param)).all():
KeyboardInterrupt
Environment:
	Python: 3.6.8
	PyTorch: 1.8.1+cu111
	Torchvision: 0.9.1+cu111
	CUDA: 11.1
	CUDNN: 8005
	NumPy: 1.19.5
	PIL: 8.3.1
Args:
	algorithm: KL
	checkpoint_freq: None
	data_dir: /scratch/local/ssd/tuan/data/
	dataset: RotatedMNIST
	epochs: None
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_adaptation
	test_envs: [4]
	train_envs: [0]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	augment_softmax: 0.0
	batch_size: 256
	class_balanced: False
	data_augmentation: True
	kl_reg: 0.3
	kl_reg_aux: 0.1
	lr: 0.001
	nonlinear_classifier: False
	num_samples: 20
	resnet18: True
	resnet_dropout: 0.0
	specify_zdim: True
	weight_decay: 0.0
	z_dim: 256
cuda
/homes/55/tuan/installations/tnew/lib64/python3.6/site-packages/torchvision/transforms/functional.py:936: UserWarning: Argument resample is deprecated and will be removed since v0.10.0. Please, use interpolation instead
  "Argument resample is deprecated and will be removed since v0.10.0. Please, use interpolation instead"
env0_out_acc  env4_in_acc   env4_out_acc  epoch         kl            kl_aux        loss          step          step_time    
0.1153021860  0.1113254045  0.1200171453  0.0000000000  0.7436825037  0.7058237195  2.4584307671  0             1.6743752956 
0.2070295757  0.2030429658  0.2100300043  1.0000000000  0.0444934004  0.0497794549  2.3587817748  36            0.0928054982 
0.2567509644  0.2628308154  0.2713244749  2.0000000000  0.0605024778  0.0728528533  2.1198354363  72            0.0816912320 
0.3064723532  0.3151183971  0.3129018431  3.0000000000  0.0791337424  0.0865825050  1.9617735942  108           0.0788772835 
0.3613373339  0.3549769635  0.3489069867  4.0000000000  0.0963948054  0.1048347486  1.8316171103  144           0.0828340915 
0.3574796399  0.3382620808  0.3450492928  5.0000000000  0.1089868777  0.1208015747  1.7839087215  180           0.0807341867 
0.4522074582  0.3912996893  0.3831975997  6.0000000000  0.1805462887  0.1807485537  1.6317522360  216           0.0829104251 
0.4984997857  0.3980499304  0.3951993142  7.0000000000  0.1940735794  0.2161757499  1.5240334736  252           0.0821174847 
0.5315045006  0.3990142505  0.4042006001  8.0000000000  0.2351809889  0.2367247194  1.3968221479  288           0.0791225698 
0.6180882983  0.4082288653  0.4102014574  9.0000000000  0.2665628642  0.2848843303  1.2287337118  324           0.0806101759 
0.6965280754  0.3962284367  0.4076296614  10.000000000  0.3269461559  0.3675370614  1.1221055587  360           0.0795147419 
0.8144020574  0.4564448730  0.4620660094  11.000000000  0.3751871867  0.3978425745  0.9909835160  396           0.0789542132 
0.8842691813  0.4523732990  0.4530647235  12.000000000  0.4217509495  0.4700257944  0.8124017666  432           0.0844053162 
0.8786969567  0.4941605057  0.5010715817  13.000000000  0.4289375560  0.4659450038  0.7047831135  468           0.0877683428 
0.9125589370  0.5153755491  0.5225032147  14.000000000  0.4372511788  0.4568199631  0.6290677902  504           0.0826502906 
0.8984140592  0.5132326155  0.5177882555  15.000000000  0.4246424188  0.4432702925  0.5732619059  540           0.0791635911 
0.9125589370  0.5311261116  0.5383626232  16.000000000  0.4380748967  0.4555476424  0.5043657265  576           0.0783782270 
0.9288469781  0.5575913425  0.5709387055  17.000000000  0.4341528250  0.4616707414  0.4808348318  612           0.0791323913 
0.9258465495  0.5521268617  0.5537933991  18.000000000  0.4097110579  0.4347169962  0.4610902940  648           0.0797812608 
0.9151307330  0.5693774778  0.5627946850  19.000000000  0.4276961022  0.4389528500  0.4267701921  684           0.0815312995 
0.9357051007  0.5999142827  0.6082297471  20.000000000  0.4186451170  0.4126901643  0.3949899036  720           0.0810930000 
0.9391341620  0.6008786028  0.6052293185  21.000000000  0.4057921883  0.4363415341  0.3865324342  756           0.0787505772 
0.9421345907  0.6181292189  0.6150878697  22.000000000  0.3971611162  0.4203696301  0.3611673026  792           0.0772490435 
0.9348478354  0.6173791921  0.6116588084  23.000000000  0.4033209715  0.4058833503  0.3480459626  828           0.0800477796 
0.9361337334  0.6305582342  0.6283754822  24.000000000  0.3964108792  0.4118145837  0.3385296009  864           0.0808005532 
0.9447063866  0.6481302904  0.6498071153  25.000000000  0.3866500689  0.3887371139  0.3162805612  900           0.0833935936 
0.9498499786  0.6451301832  0.6455207887  26.000000000  0.3909045905  0.3652340968  0.3074602766  936           0.0786875420 
0.9378482640  0.6625950927  0.6630947278  27.000000000  0.3752113266  0.3814641618  0.3127401119  972           0.0806133350 
0.9507072439  0.6648451730  0.6686669524  28.000000000  0.3808931162  0.3749341087  0.2837775490  1008          0.0797469219 
0.9472781826  0.6703096539  0.6669524218  29.000000000  0.3798750722  0.3716595587  0.2820052136  1044          0.0789940887 
0.9468495499  0.6834886960  0.6840977282  30.000000000  0.3756602307  0.3558231261  0.2704759219  1080          0.0788210366 
0.9507072439  0.6947390978  0.7012430347  31.000000000  0.3747426503  0.3416473849  0.2570391939  1116          0.0806471441 
0.9532790399  0.6846673095  0.6828118303  32.000000000  0.3637206207  0.3308782097  0.2523304944  1152          0.0775892470 
0.9532790399  0.6923818708  0.6952421775  33.000000000  0.3680638820  0.3514533589  0.2625269555  1188          0.0845938987 
0.9524217745  0.7002035787  0.7042434634  34.000000000  0.3491180208  0.3229625358  0.2239081288  1224          0.0827010804 
0.9494213459  0.6850958963  0.6909558508  35.000000000  0.3531115883  0.3304523180  0.2181794325  1260          0.0775714649 
0.9519931419  0.7093110468  0.7158165452  36.000000000  0.3366226256  0.3115049584  0.2100643048  1296          0.0806253089 
0.9567081012  0.7035251259  0.7076725246  37.000000000  0.3428471867  0.3180258522  0.2223329354  1332          0.0809701747 
0.9571367338  0.7101682203  0.7162451779  38.000000000  0.3407652941  0.3107627100  0.2004828900  1368          0.0802162422 
0.9511358766  0.7176684882  0.7243891985  39.000000000  0.3352809466  0.3175847944  0.1991873379  1404          0.0794012149 
0.9588512645  0.7217400621  0.7252464638  40.000000000  0.3253262887  0.3019020988  0.1903596113  1440          0.0817636119 
0.9575653665  0.7300975035  0.7368195456  41.000000000  0.3141414076  0.3136424687  0.1729732725  1476          0.0807366570 
0.9541363052  0.7234544091  0.7278182598  42.000000000  0.3215784447  0.3100093885  0.1820246023  1512          0.0843277176 
0.9567081012  0.7244187292  0.7299614231  43.000000000  0.3229679217  0.3087922732  0.1774804491  1548          0.0802854167 
0.9515645092  0.7224900889  0.7162451779  44.000000000  0.3243381911  0.3036496689  0.1663161237  1584          0.0807305243 
0.9605657951  0.7296689167  0.7346763823  45.000000000  0.3155018588  0.2891377144  0.1726718156  1620          0.0793637832 
0.9541363052  0.7306332369  0.7325332190  46.000000000  0.3174244314  0.2814445264  0.1655987990  1656          0.0815595521 
0.9605657951  0.7483124397  0.7513930562  47.000000000  0.2954652541  0.2866273406  0.1492796880  1692          0.0818604827 
0.9545649378  0.7347048109  0.7368195456  48.000000000  0.3197806180  0.2816113813  0.1671771428  1728          0.0806783239 
0.9562794685  0.7426336655  0.7453921989  49.000000000  0.2995605336  0.2959483018  0.1537534532  1764          0.0812979274 
0.9605657951  0.7444551591  0.7509644235  50.000000000  0.2951056063  0.2740713855  0.1424571276  1800          0.0792404413 
0.9605657951  0.7445623058  0.7509644235  51.000000000  0.3120076474  0.2956907219  0.1480532516  1836          0.0790958934 
0.9575653665  0.7459552127  0.7526789541  52.000000000  0.3210592849  0.2938103444  0.1282483499  1872          0.0833783878 
0.9627089584  0.7527054538  0.7561080154  53.000000000  0.2845917212  0.2719432314  0.1328202892  1908          0.0805179013 
0.9657093871  0.7518482803  0.7526789541  54.000000000  0.3006755412  0.2565703276  0.1269936094  1944          0.0848017269 
0.9579939991  0.7524911604  0.7531075868  55.000000000  0.2921549579  0.2724718286  0.1337557592  1980          0.0817197760 
0.9631375911  0.7596699882  0.7633947707  56.000000000  0.2870406922  0.2665233579  0.1281526101  2016          0.0803556376 
0.9652807544  0.7604200150  0.7668238320  57.000000000  0.2862794648  0.2726012170  0.1163975943  2052          0.0801021987 
0.9592798971  0.7583842280  0.7625375054  58.000000000  0.2910205937  0.2695634332  0.1219009832  2088          0.0824168192 
0.9635662237  0.7590271081  0.7612516074  59.000000000  0.2791740331  0.2635258519  0.1159875425  2124          0.0796657271 
0.9635662237  0.7663130826  0.7719674239  60.000000000  0.2950934851  0.2634864201  0.1178771390  2160          0.0796408653 
0.9614230604  0.7610628951  0.7633947707  61.000000000  0.2775818573  0.2586078528  0.1099223958  2196          0.0783303446 
0.9618516931  0.7603128683  0.7672524646  62.000000000  0.2759028524  0.2472012440  0.1150734044  2232          0.0831364128 
0.9597085298  0.7611700418  0.7582511787  63.000000000  0.2567306956  0.2291909125  0.1096323481  2268          0.0801743666 
0.9644234891  0.7663130826  0.7629661380  64.000000000  0.2731704977  0.2405283815  0.1094693654  2304          0.0806277262 
0.9579939991  0.7654559091  0.7689669953  65.000000000  0.2734919985  0.2382031050  0.0966416266  2340          0.0774165723 
0.9639948564  0.7670631094  0.7698242606  66.000000000  0.2640663816  0.2669821282  0.0932171048  2376          0.0773286952 
0.9609944278  0.7701703632  0.7723960566  67.000000000  0.2650229070  0.2426252696  0.1070227155  2412          0.0800617933 
0.9627089584  0.7623486553  0.7655379340  68.000000000  0.2758058276  0.2502818935  0.0958788495  2448          0.0790058573 
0.9622803258  0.7673845494  0.7676810973  69.000000000  0.2596507205  0.2399468405  0.0889309182  2484          0.0796602103 
0.9661380197  0.7744562306  0.7723960566  70.000000000  0.2438842058  0.2258532445  0.0853332752  2520          0.0781017211 
0.9601371625  0.7708132433  0.7685383626  71.000000000  0.2610545440  0.2304742899  0.0885092978  2556          0.0812971128 
0.9601371625  0.7775634844  0.7779682812  72.000000000  0.2505694595  0.2255737467  0.0924368621  2592          0.0820540786 
0.9584226318  0.7714561234  0.7728246892  73.000000000  0.2484791643  0.2212884327  0.0839116670  2628          0.0817533996 
0.9567081012  0.7709203900  0.7723960566  74.000000000  0.2450916767  0.2234293222  0.0858484549  2664          0.0795491139 
0.9648521217  0.7754205507  0.7801114445  75.000000000  0.2645516495  0.2357626590  0.0844267551  2700          0.0799541341 
0.9648521217  0.7789563913  0.7766823832  76.000000000  0.2467318194  0.2159442206  0.0822839112  2736          0.0809198949 
0.9627089584  0.7758491375  0.7813973425  77.000000000  0.2603394720  0.2158698075  0.0778533386  2772          0.0847601758 
0.9644234891  0.7782063645  0.7749678526  78.000000000  0.2597103351  0.2322567403  0.0760366212  2808          0.0789756113 
0.9609944278  0.7772420444  0.7801114445  79.000000000  0.2369329764  0.2144081361  0.0773518438  2844          0.0794493092 
0.9652807544  0.7770277510  0.7762537505  80.000000000  0.2396243645  0.2115528385  0.0741844662  2880          0.0782124135 
0.9627089584  0.7845280189  0.7891127304  81.000000000  0.2413065202  0.2137524916  0.0727235591  2916          0.0793806447 
0.9639948564  0.7851708990  0.7912558937  82.000000000  0.2417300741  0.2099542055  0.0769891264  2952          0.0835152600 
0.9639948564  0.7808850316  0.7818259751  83.000000000  0.2366191083  0.1989189287  0.0685247177  2988          0.0813839833 
0.9721388770  0.7812064717  0.7882554651  84.000000000  0.2330151399  0.2014310128  0.0689682679  3024          0.0828131239 
0.9648521217  0.7835636987  0.7835405058  85.000000000  0.2378386392  0.2057354516  0.0662122370  3060          0.0798493558 
0.9609944278  0.7839922854  0.7903986284  86.000000000  0.2309353782  0.2037695381  0.0599911194  3096          0.0783948368 
0.9678525504  0.7802421515  0.7813973425  87.000000000  0.2192408807  0.2069562740  0.0742953385  3132          0.0808952914 
0.9682811830  0.7792778314  0.7796828118  88.000000000  0.2239381770  0.2072379357  0.0674633382  3168          0.0891336401 
0.9674239177  0.7825993785  0.7882554651  89.000000000  0.2189535466  0.1917895277  0.0610051399  3204          0.0803546707 
0.9639948564  0.7830279653  0.7856836691  90.000000000  0.2121196124  0.1851252649  0.0625418976  3240          0.0811081860 
0.9665666524  0.7831351120  0.7856836691  91.000000000  0.2166937292  0.1988538702  0.0607725168  3276          0.0810641514 
Traceback (most recent call last):
  File "/usr/lib64/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib64/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/homes/55/tuan/KL/scripts/train.py", line 253, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/homes/55/tuan/KL/lib/misc.py", line 118, in accuracy
    p = network.predict(x)
  File "/homes/55/tuan/KL/algorithms.py", line 231, in predict
    z_dist = dist.Independent(dist.normal.Normal(z_mu,z_sigma),1)
  File "/homes/55/tuan/installations/tnew/lib64/python3.6/site-packages/torch/distributions/normal.py", line 50, in __init__
    super(Normal, self).__init__(batch_shape, validate_args=validate_args)
  File "/homes/55/tuan/installations/tnew/lib64/python3.6/site-packages/torch/distributions/distribution.py", line 52, in __init__
    if not constraint.check(getattr(self, param)).all():
KeyboardInterrupt
Environment:
	Python: 3.6.8
	PyTorch: 1.8.1+cu111
	Torchvision: 0.9.1+cu111
	CUDA: 11.1
	CUDNN: 8005
	NumPy: 1.19.5
	PIL: 8.3.1
Args:
	algorithm: KL
	checkpoint_freq: None
	data_dir: /scratch/local/ssd/tuan/data/
	dataset: RotatedMNIST
	epochs: None
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_adaptation
	test_envs: [5]
	train_envs: [0]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	augment_softmax: 0.0
	batch_size: 256
	class_balanced: False
	data_augmentation: True
	kl_reg: 0.3
	kl_reg_aux: 0.1
	lr: 0.001
	nonlinear_classifier: False
	num_samples: 20
	resnet18: True
	resnet_dropout: 0.0
	specify_zdim: True
	weight_decay: 0.0
	z_dim: 256
cuda
/homes/55/tuan/installations/tnew/lib64/python3.6/site-packages/torchvision/transforms/functional.py:936: UserWarning: Argument resample is deprecated and will be removed since v0.10.0. Please, use interpolation instead
  "Argument resample is deprecated and will be removed since v0.10.0. Please, use interpolation instead"
env0_out_acc  env5_in_acc   env5_out_acc  epoch         kl            kl_aux        loss          step          step_time    
0.1157308187  0.1118611379  0.1075867981  0.0000000000  0.8752634525  0.7786460519  2.4584307671  0             1.7878475189 
0.2284612087  0.2168648880  0.2314616374  1.0000000000  0.0415876475  0.0487583180  2.3538123369  36            0.0930114521 
0.2627518217  0.2645451623  0.2618945564  2.0000000000  0.0644186884  0.0715990729  2.1128424472  72            0.0794336796 
0.2991855979  0.2821172185  0.2897556794  3.0000000000  0.0811778555  0.0885213597  1.9684335821  108           0.0775589612 
0.3013287613  0.2889746062  0.2991855979  4.0000000000  0.0929740551  0.0825522128  1.9085989760  144           0.0779187348 
0.3501928847  0.3240115718  0.3296185169  5.0000000000  0.1192318632  0.1218318310  1.8051632014  180           0.0797553327 
0.4440634376  0.3890496089  0.3934847835  6.0000000000  0.1538275050  0.1413931135  1.7120388448  216           0.0804737144 
0.4624946421  0.3757634201  0.3557651093  7.0000000000  0.1928578632  0.2103191068  1.5842794644  252           0.0780428317 
0.5670810116  0.4098360656  0.4114873553  8.0000000000  0.2238153368  0.2401955194  1.4580053190  288           0.0786869725 
0.6210887270  0.4153005464  0.4114873553  9.0000000000  0.2859331717  0.2953370611  1.2936195897  324           0.0794360969 
0.7033861980  0.3975141969  0.3986283755  10.000000000  0.3283920354  0.3515235103  1.1956955261  360           0.0776851508 
0.6793827690  0.3914068360  0.3853407630  11.000000000  0.3783847524  0.3963958389  1.0845391999  396           0.0766621629 
0.8345477925  0.3978356370  0.3900557222  12.000000000  0.4082006117  0.4437596086  0.9432738043  432           0.0759012302 
0.7668238320  0.3841208615  0.3814830690  13.000000000  0.4155797346  0.4733530415  0.8092531694  468           0.0804746946 
0.8894127733  0.4384442302  0.4324903558  14.000000000  0.4291992005  0.4979488916  0.7318617917  504           0.0787854989 
0.8859837120  0.4619093539  0.4714959280  15.000000000  0.4450746940  0.4690591163  0.6693737060  540           0.0781539480 
0.9087012430  0.4803385835  0.4813544792  16.000000000  0.4418166760  0.4809943537  0.5693504322  576           0.0797500677 
0.9125589370  0.4852673310  0.4916416631  17.000000000  0.4450153493  0.4726494501  0.5664759138  612           0.0771267348 
0.9159879983  0.4829101039  0.4860694385  18.000000000  0.4140625182  0.4624158094  0.4975862097  648           0.0766654942 
0.9018431204  0.4846244509  0.4800685812  19.000000000  0.4480452091  0.4793512970  0.4730208500  684           0.0769310064 
0.9279897128  0.5184828030  0.5182168881  20.000000000  0.4396992524  0.4378596577  0.4516019771  720           0.0767782132 
0.9262751822  0.5271616843  0.5220745821  21.000000000  0.4212390168  0.4464660750  0.4294980516  756           0.0764116777 
0.9374196314  0.5190185364  0.5126446635  22.000000000  0.4002100312  0.4450632085  0.3792297567  792           0.0799198813 
0.9361337334  0.5146255223  0.5199314188  23.000000000  0.4250607673  0.4500030097  0.3840972251  828           0.0778407719 
0.9365623661  0.5333761920  0.5345049293  24.000000000  0.4007509698  0.4160113749  0.3728352429  864           0.0772504740 
0.9262751822  0.5437694203  0.5430775825  25.000000000  0.3982622160  0.4119122922  0.3544446176  900           0.0780452291 
0.9357051007  0.5546983821  0.5533647664  26.000000000  0.4001331975  0.4028934373  0.3352200968  936           0.0775723391 
0.9369909987  0.5326261652  0.5379339906  27.000000000  0.4009145184  0.4204652111  0.3503000604  972           0.0777783990 
0.9485640806  0.5676631308  0.5773681955  28.000000000  0.3951238195  0.3997559746  0.3092987869  1008          0.0774196519 
0.9378482640  0.5678774242  0.5692241749  29.000000000  0.3926565879  0.4172717995  0.3337827383  1044          0.0764315791 
0.9395627947  0.5565198757  0.5589369910  30.000000000  0.3932787544  0.4008950144  0.3004720828  1080          0.0782769786 
0.9455636520  0.5782706525  0.5795113588  31.000000000  0.3961580247  0.3965464549  0.3006275814  1116          0.0794499384 
0.9464209173  0.5756991321  0.5765109301  32.000000000  0.3904161851  0.4029393279  0.2856904426  1152          0.0779787170 
0.9532790399  0.5868423872  0.5893699100  33.000000000  0.3771596120  0.3860916975  0.2816152345  1188          0.0766677062 
0.9489927132  0.6036644166  0.6039434205  34.000000000  0.3783936699  0.3655511058  0.2531217308  1224          0.0819957455 
0.9442777540  0.5762348655  0.5730818688  35.000000000  0.3661411968  0.3607677536  0.2559063973  1260          0.0808289713 
0.9537076725  0.6008786028  0.6065152165  36.000000000  0.3658547385  0.3550301343  0.2393945435  1296          0.0777782864 
0.9404200600  0.5950926819  0.6005143592  37.000000000  0.3749203616  0.3578483032  0.2634680950  1332          0.0773517291 
0.9507072439  0.6037715633  0.6086583798  38.000000000  0.3637508700  0.3590858579  0.2306888021  1368          0.0766048233 
0.9507072439  0.6123432980  0.6086583798  39.000000000  0.3560763531  0.3428872956  0.2143502538  1404          0.0773149067 
0.9528504072  0.6129861781  0.6099442778  40.000000000  0.3525406371  0.3451200939  0.2317638194  1440          0.0784560508 
0.9545649378  0.6187720990  0.6180882983  41.000000000  0.3667881721  0.3641290930  0.2251166585  1476          0.0784315136 
0.9477068153  0.6032358299  0.5983711959  42.000000000  0.3787827806  0.3537922270  0.2302818319  1512          0.0770178172 
0.9584226318  0.6186649523  0.6198028290  43.000000000  0.3365968085  0.3275601996  0.2092932020  1548          0.0772664944 
0.9498499786  0.6140576449  0.6206600943  44.000000000  0.3544376989  0.3331791957  0.1933687901  1584          0.0788333019 
0.9601371625  0.6247723133  0.6258036862  45.000000000  0.3494348807  0.3378756692  0.1999679299  1620          0.0775549743 
0.9498499786  0.5981999357  0.6022288898  46.000000000  0.3586138950  0.3397012419  0.2137248620  1656          0.0774042209 
0.9515645092  0.6360227151  0.6390912988  47.000000000  0.3348121014  0.3337844445  0.1882059876  1692          0.0771140191 
0.9549935705  0.6278795671  0.6356622375  48.000000000  0.3449698091  0.3459461199  0.1805734988  1728          0.0762635138 
0.9579939991  0.6343083682  0.6382340334  49.000000000  0.3332871579  0.3050104893  0.1810499922  1764          0.0762171547 
0.9601371625  0.6313082610  0.6386626661  50.000000000  0.3481920544  0.2971732020  0.1727478643  1800          0.0778546731 
0.9661380197  0.6338797814  0.6425203601  51.000000000  0.3308212128  0.3150872704  0.1596004510  1836          0.0774113933 
0.9592798971  0.6404157291  0.6352336048  52.000000000  0.3150336196  0.3057078669  0.1553032239  1872          0.0778911908 
0.9631375911  0.6407371692  0.6438062580  53.000000000  0.3048557291  0.2974131058  0.1632125808  1908          0.0777190924 
0.9567081012  0.6437372763  0.6515216459  54.000000000  0.3213079472  0.3025177932  0.1682109363  1944          0.0767292579 
0.9554222032  0.6502732240  0.6515216459  55.000000000  0.3269310080  0.3063824077  0.1532172964  1980          0.0784238577 
0.9597085298  0.6485588771  0.6570938706  56.000000000  0.3146981564  0.2886130777  0.1456292988  2016          0.0782394409 
0.9567081012  0.6468445302  0.6502357480  57.000000000  0.3100900998  0.2787630194  0.1315227215  2052          0.0780016581 
0.9609944278  0.6561662917  0.6532361766  58.000000000  0.3182413313  0.2818057057  0.1381294959  2088          0.0770121879 
0.9562794685  0.6467373835  0.6575225032  59.000000000  0.2971014645  0.2881460405  0.1468058378  2124          0.0793787969 
0.9537076725  0.6666666667  0.6690955851  60.000000000  0.3216460413  0.2925116171  0.1395668472  2160          0.0788896283 
0.9657093871  0.6520947177  0.6528075439  61.000000000  0.3075187339  0.2884468651  0.1433050268  2196          0.0781246490 
0.9622803258  0.6556305582  0.6613801972  62.000000000  0.3131405910  0.2919974327  0.1405137990  2232          0.0781005621 
0.9605657951  0.6612021858  0.6618088298  63.000000000  0.2948382099  0.2833343496  0.1253250084  2268          0.0763422847 
0.9597085298  0.6540233580  0.6553793399  64.000000000  0.2985874563  0.2813796931  0.1316674604  2304          0.0761424700 
0.9498499786  0.6515589842  0.6566652379  65.000000000  0.2908744779  0.2569218046  0.1147447835  2340          0.0763099988 
0.9571367338  0.6512375442  0.6536648093  66.000000000  0.3040133384  0.2714654356  0.1220560821  2376          0.0763655437 
0.9592798971  0.6526304511  0.6549507072  67.000000000  0.3106109632  0.2636214577  0.1261163174  2412          0.0771671269 
0.9627089584  0.6518804243  0.6545220746  68.000000000  0.3069537050  0.2670190897  0.1261577376  2448          0.0773095025 
0.9601371625  0.6541305047  0.6643806258  69.000000000  0.2866626812  0.2753015326  0.1257031504  2484          0.0765770608 
0.9639948564  0.6630236794  0.6695242177  70.000000000  0.2940197355  0.2718174921  0.1079953048  2520          0.0766746336 
0.9519931419  0.6517732776  0.6570938706  71.000000000  0.2958048764  0.2656507724  0.1092023096  2556          0.0781638225 
0.9579939991  0.6493089039  0.6523789113  72.000000000  0.3102330334  0.2715021405  0.1296726635  2592          0.0767468479 
0.9584226318  0.6594878389  0.6648092585  73.000000000  0.3064791030  0.2756812473  0.1102638040  2628          0.0770172742 
0.9541363052  0.6637737062  0.6690955851  74.000000000  0.2835781508  0.2609099845  0.1100576534  2664          0.0772648321 
0.9507072439  0.6454516233  0.6493784826  75.000000000  0.2849829959  0.2654502905  0.1129976016  2700          0.0769638485 
0.9592798971  0.6659166399  0.6660951565  76.000000000  0.2886179123  0.2623391118  0.1050432995  2736          0.0769572722 
0.9631375911  0.6602378656  0.6635233605  77.000000000  0.2727235721  0.2656203442  0.1034058388  2772          0.0761746301 
0.9627089584  0.6625950927  0.6635233605  78.000000000  0.2921522293  0.2530287902  0.0973380799  2808          0.0767528547 
0.9597085298  0.6578806386  0.6665237891  79.000000000  0.2769473361  0.2393905769  0.0932303236  2844          0.0777565175 
0.9545649378  0.6554162649  0.6583797685  80.000000000  0.2750126057  0.2450392445  0.0997854066  2880          0.0771218737 
0.9644234891  0.6676309868  0.6759537077  81.000000000  0.2751396828  0.2425723407  0.1063980540  2916          0.0799918506 
0.9627089584  0.6590592521  0.6660951565  82.000000000  0.2579433819  0.2432625194  0.0864986163  2952          0.0765394370 
0.9592798971  0.6555234116  0.6570938706  83.000000000  0.2693664498  0.2471567955  0.0937731293  2988          0.0761544440 
0.9588512645  0.6582020786  0.6605229318  84.000000000  0.2579414447  0.2415993412  0.0883780841  3024          0.0770603220 
0.9592798971  0.6763098682  0.6780968710  85.000000000  0.2710645530  0.2437432110  0.0897452171  3060          0.0779631403 
0.9639948564  0.6666666667  0.6673810544  86.000000000  0.2724558777  0.2523057825  0.0823048506  3096          0.0782438318 
0.9648521217  0.6712739741  0.6768109730  87.000000000  0.2587576972  0.2349121306  0.0903260671  3132          0.0767749747 
0.9597085298  0.6677381335  0.6669524218  88.000000000  0.2730383608  0.2565642960  0.0870147069  3168          0.0784134401 
0.9665666524  0.6708453873  0.6703814831  89.000000000  0.2483494447  0.2186417679  0.0831950696  3204          0.0775369604 
0.9665666524  0.6697739205  0.6729532790  90.000000000  0.2383271555  0.2269794544  0.0795057325  3240          0.0792738862 
0.9584226318  0.6691310404  0.6738105444  91.000000000  0.2592501243  0.2348324756  0.0810633982  3276          0.0775778161 
0.9627089584  0.6676309868  0.6742391770  92.000000000  0.2477137446  0.2246144911  0.0786004732  3312          0.0773587690 
0.9601371625  0.6759884282  0.6768109730  93.000000000  0.2651237978  0.2349717551  0.0844706726  3348          0.0765779217 
0.9627089584  0.6733097611  0.6750964423  94.000000000  0.2523193260  0.2180914217  0.0761245419  3384          0.0763509737 
0.9639948564  0.6664523733  0.6669524218  95.000000000  0.2545056873  0.2269150780  0.0790524370  3420          0.0780558983 
0.9597085298  0.6797385621  0.6853836262  96.000000000  0.2534286049  0.2318970760  0.0855926087  3456          0.0762723883 
Traceback (most recent call last):
  File "/usr/lib64/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib64/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/homes/55/tuan/KL/scripts/train.py", line 236, in <module>
    step_vals = algorithm.update(minibatches_device, uda_device)
  File "/homes/55/tuan/KL/algorithms.py", line 223, in update
    return {'loss': loss.item(), 'kl': kl.item(), 'kl_aux': kl_aux.item()}
KeyboardInterrupt
